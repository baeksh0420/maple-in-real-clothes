{"cells":[{"cell_type":"markdown","metadata":{"id":"_XHgFb43_0QY"},"source":["## SSH 키를 이용하여 깃 프로젝트 연동하기\n","- 최초 1번 실행"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TY26c7emjTnc","outputId":"272972f1-ee87-4cb1-d60f-4dbe53158996","executionInfo":{"status":"ok","timestamp":1655299097629,"user_tz":-540,"elapsed":20733,"user":{"displayName":"코쿤팬","userId":"14151456840722636307"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhwESnegydBA","outputId":"b7ddc030-aa9e-4bac-a43e-110182bca03b","executionInfo":{"status":"ok","timestamp":1655299457038,"user_tz":-540,"elapsed":5,"user":{"displayName":"코쿤팬","userId":"14151456840722636307"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/gan/PJ_01_local_maple\n"]}],"source":["%cd /content/drive/MyDrive/gan/PJ_01_local_maple"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNVT85fpVq1K","outputId":"efd5519f-b0c6-4e8e-8d91-fbecdacfc293"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating public/private rsa key pair.\n","Enter file in which to save the key (/root/.ssh/id_rsa): \n","Created directory '/root/.ssh'.\n","Enter passphrase (empty for no passphrase): \n","Enter same passphrase again: \n","Your identification has been saved in /root/.ssh/id_rsa.\n","Your public key has been saved in /root/.ssh/id_rsa.pub.\n","The key fingerprint is:\n","SHA256:02fdrU1xEUAKnpeVP84DaiuUjUiYqQKFsKAALBvNz1A root@f89c57f95313\n","The key's randomart image is:\n","+---[RSA 2048]----+\n","|O+ .E    .  .+oo.|\n","|Bo=     . o +.  .|\n","|++ +  +  o +  ...|\n","|o   o+ . ..  o ++|\n","|.   . . S = + = =|\n","| . .   . = *   B |\n","|  .     . . . . o|\n","|         . .     |\n","|          .      |\n","+----[SHA256]-----+\n"]}],"source":["# ssh 키 생성\n","# /root/.ssh/ 폴더에 id_rsa.pub(공개키)와 id_rsa(개인키) 파일이 생성된다.\n","\n","# 중간중간 뜨는건 아무것도 입력하지 않고 엔터를 누르면 된다!\n","\n","!ssh-keygen"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Wq7t3kSV3Wf","outputId":"9884dbe6-1cf2-417a-ac6c-879b5cde7486"},"outputs":[{"name":"stdout","output_type":"stream","text":["ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsE6wkclMDafNLZCgRioadotKYZrMks+uBcd5qChcomZPit9zrGk24nirH0AtITx6ysQSSId4r7q7akqah62N2flFuTjgFCVKCAHUBiSz6RxM43AfbkKxWjr2s5LAMi1p302xps7SDt2kBxKIQPi5kyeR2Np3r6OiVSj/RdMG1s+musTXDXyxdeHUEb6aBPAmlhr0NAn18m8d1XtMpNYrLwbUk3RQhThqK0QMWMTxbVQix4GONuHdWJLAqvRN+z7M+6v6UHWjujQrOv9x2ZHmCnvPIa1Ng0tpkOYFJzzOLo1U8UhMz0XJK0lF5/1+s0TK805UJwZ+AWcD0IS3EOvZL root@f89c57f95313\n"]}],"source":["# 공개키를 복사하여 깃허브 ssh에 등록\n","! cat ~/.ssh/id_rsa.pub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3RnWt_X_F2y","outputId":"d9c6c9dd-64d4-476f-8059-50ced3b558dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["# github.com:22 SSH-2.0-babeld-406cafbd\n"]}],"source":["# 알려진 호스트(known hosts)에 GitHub 호스트 주소 넣기 \n","!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlGVcST8Wqoe","outputId":"85b42012-ed71-402e-8d31-6b3c613342a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/gan/PJ_01_working\n"]}],"source":["# 깃 저장소를 클론할 폴더로 이동\n","%cd /content/drive/MyDrive/gan/PJ_01_working"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JLYuWjgU-4tb","outputId":"d01028be-2d44-4a4d-f93b-da9cb89f6ff3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'PJ_01'...\n","Warning: Permanently added the RSA host key for IP address '140.82.113.3' to the list of known hosts.\n","remote: Enumerating objects: 569, done.\u001b[K\n","remote: Counting objects: 100% (404/404), done.\u001b[K\n","remote: Compressing objects: 100% (328/328), done.\u001b[K\n","remote: Total 569 (delta 128), reused 336 (delta 66), pack-reused 165\u001b[K\n","Receiving objects: 100% (569/569), 171.74 MiB | 11.20 MiB/s, done.\n","Resolving deltas: 100% (158/158), done.\n","Checking out files: 100% (165/165), done.\n"]}],"source":["# private repository를 클론\n","!git clone git@github.com:shyun46/PJ_01.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeUKBatvoE2V","outputId":"56752cca-cea1-4786-8410-ed6f50821573"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/gan/PJ_01_working/PJ_01\n"]}],"source":["# !git init\n","%cd /content/drive/MyDrive/gan/PJ_01_working/PJ_01"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPDuiZhYAchW"},"outputs":[],"source":["# 본인 브랜치 생성\n","! git branch feature/olive46"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0upgO-9_Ae2d","outputId":"8398d980-a8dc-4c5b-cec7-b1350501e128"},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: Permanently added the RSA host key for IP address '140.82.112.4' to the list of known hosts.\n","Total 0 (delta 0), reused 0 (delta 0)\n","remote: \n","remote: Create a pull request for 'feature/olive46' on GitHub by visiting:\u001b[K\n","remote:      https://github.com/shyun46/PJ_01/pull/new/feature/olive46\u001b[K\n","remote: \n","To github.com:shyun46/PJ_01.git\n"," * [new branch]      feature/olive46 -> feature/olive46\n","Branch 'feature/olive46' set up to track remote branch 'feature/olive46' from 'origin'.\n"]}],"source":["# 생성한 브랜치 push\n","! git push --set-upstream origin feature/olive46"]},{"cell_type":"markdown","metadata":{"id":"l3oJZqpUABbM"},"source":["## 프로젝트에 PUSH 하기\n","- 파일 변경 시 항상 실행"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWCTGgIHmo_R","outputId":"4bac2c3c-e7ff-4545-fd63-fc319016e825"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/gan/PJ_01_working/PJ_01\n"]}],"source":["# 1. 깃 프로젝트가 담긴 폴더로 이동\n","%cd /content/drive/MyDrive/gan/PJ_01_working/PJ_01"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlHeVkqUskWV","outputId":"36f544c8-b09e-404c-f3ba-ff0028be5f61"},"outputs":[{"name":"stdout","output_type":"stream","text":["# github.com:22 SSH-2.0-babeld-406cafbd\n"]}],"source":["# 2. 알려진 호스트(known hosts)에 GitHub 호스트 주소 넣기 (매번 해주는게 맞나?)\n","!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AeH63xXjnfpv"},"outputs":[],"source":["# 3. 계정정보 입력\n","! git config --global user.email \"olive46@gmail.com\"\n","! git config --global user.name \"olive46\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7HoyNrA-9c9","outputId":"67788359-020a-4d0d-8b95-4cb3f5056332"},"outputs":[{"name":"stdout","output_type":"stream","text":["Switched to branch 'feature/olive46'\n","Your branch is up to date with 'origin/feature/olive46'.\n","* \u001b[32mfeature/olive46\u001b[m\n","  main\u001b[m\n"]}],"source":["# 4. 본인 브랜치로 이동\n","! git checkout feature/olive46\n","! git branch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yJRUC7J_aoK"},"outputs":[],"source":["# 5. 파일 변경 후 PUSH\n","f = open('test.txt', 'w')\n","\n","f.write(\"TEST\")\n","\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyH4xAAW_Rfl"},"outputs":[],"source":["! git add test.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrWlvHXq_W2x","outputId":"28f419de-5e8b-4073-d372-384a1fb2588d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[feature/olive46 bb1b616] olive46_test\n"," 1 file changed, 1 insertion(+)\n"," create mode 100644 test.txt\n"]}],"source":["! git commit -m \"olive46_test\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8fAqY5g_ha1","outputId":"51ebf750-f5eb-4f42-bae5-411783cbff60"},"outputs":[{"name":"stdout","output_type":"stream","text":["Counting objects: 3, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (2/2), done.\n","Writing objects: 100% (3/3), 264 bytes | 88.00 KiB/s, done.\n","Total 3 (delta 1), reused 1 (delta 0)\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","To github.com:shyun46/PJ_01.git\n","   262be0f..bb1b616  feature/olive46 -> feature/olive46\n"]}],"source":["! git push"]},{"cell_type":"markdown","metadata":{"id":"QE_kEfg7o_Ub"},"source":["## 프로젝트에 작업하기 (model.py 실행)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAyL306G_kXC","outputId":"2e95d9f0-8eed-4d8c-ad0b-c5f199de568b","executionInfo":{"status":"ok","timestamp":1655299168512,"user_tz":-540,"elapsed":24819,"user":{"displayName":"코쿤팬","userId":"14151456840722636307"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 15.5 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/sedthh/pyxelate.git\n","  Cloning https://github.com/sedthh/pyxelate.git to /tmp/pip-req-build-l7t8t0n2\n","  Running command git clone -q https://github.com/sedthh/pyxelate.git /tmp/pip-req-build-l7t8t0n2\n","Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from pyxelate==2.1.1) (1.0.2)\n","Collecting scikit-image>=0.19.1\n","  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n","\u001b[K     |████████████████████████████████| 13.5 MB 13.8 MB/s \n","\u001b[?25hCollecting numba>=0.53.1\n","  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 52.3 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->pyxelate==2.1.1) (57.4.0)\n","Collecting llvmlite<0.39,>=0.38.0rc1\n","  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","\u001b[K     |████████████████████████████████| 34.5 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy<1.23,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->pyxelate==2.1.1) (1.21.6)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (2.4.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (1.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (1.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (21.3)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (7.1.2)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.19.1->pyxelate==2.1.1) (2.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image>=0.19.1->pyxelate==2.1.1) (3.0.9)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->pyxelate==2.1.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->pyxelate==2.1.1) (1.1.0)\n","Building wheels for collected packages: pyxelate\n","  Building wheel for pyxelate (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyxelate: filename=pyxelate-2.1.1-py3-none-any.whl size=14206 sha256=163a17ddd4241ddf2bbf40c510b75c72b30f6be872d93349bcc98c0c4af6436f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-paawzsaz/wheels/2e/33/10/b5be4d740bba2dc4d3311bb6c0047214db53a7098bd88051dc\n","Successfully built pyxelate\n","Installing collected packages: llvmlite, scikit-image, numba, pyxelate\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed llvmlite-0.38.1 numba-0.55.2 pyxelate-2.1.1 scikit-image-0.19.3\n"]}],"source":["!pip install tensorboardX\n","!pip install git+https://github.com/sedthh/pyxelate.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFeJY8d_pMLA","outputId":"6a6ef2e1-f223-47c5-8a64-1a4148807b5f","executionInfo":{"status":"ok","timestamp":1655289379302,"user_tz":-540,"elapsed":9422,"user":{"displayName":"코쿤팬","userId":"14151456840722636307"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","** PIPELINE 1 (mode = live) ___________________________________________________________________________________________\n","** RUN COMMAND SCRIPT - python test.py --name gmm --stage GMM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoint/gmm/gmm_final.pth\n","\n","   [STEP : Tryon, METHOD : 1, VERSION : 0.0]  : cp-vton 논문의 pretrained checkpoint 사용한 방법\n","   \n","      |-> log :\n","      |\n","** RUN COMMAND SCRIPT - python test.py --name tom --stage TOM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoint/tom/tom_final.pth\n","\n","\n"]}],"source":["# %run model.py"]},{"cell_type":"code","source":["! python step/test.py --name gmm --stage GMM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoint/gmm/gmm_final.pth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vA9WhBG89_tD","executionInfo":{"status":"ok","timestamp":1655299545625,"user_tz":-540,"elapsed":8665,"user":{"displayName":"코쿤팬","userId":"14151456840722636307"}},"outputId":"5f66d59b-810c-4c33-ca81-9c5f8b66b57c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=4, checkpoint='checkpoint/gmm/gmm_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='data', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='gmm', radius=5, result_dir='result', shuffle=False, stage='GMM', tensorboard_dir='tensorboard', workers=4)\n","Start to test stage: GMM, named: gmm!\n","*** train_dataset is DONE! ***\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","*** train_loader is DONE! ***\n","*** visualization code is DONE! ***\n","c (256, 192, 3)\n","initialization method [normal]\n","initialization method [normal]\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","*** GMM model is Loaded! ***\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","c (256, 192, 3)\n","im <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","im_c <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","pcm <class 'torch.Tensor'> torch.Size([256, 192])\n","im_h <class 'torch.Tensor'> torch.Size([3, 256, 192])\n","phead <class 'torch.Tensor'> torch.Size([256, 192])\n","Traceback (most recent call last):\n","  File \"step/test.py\", line 172, in <module>\n","    main()\n","  File \"step/test.py\", line 155, in main\n","    test_gmm(opt, train_loader, model, board)\n","  File \"step/test.py\", line 69, in test_gmm\n","    grid, theta = model(agnostic, c) # GMM 모델 후 아웃풋\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/gan/PJ_01_local_maple/step/model.py\", line 275, in forward\n","    featureA = self.extractionA(inputA)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/MyDrive/gan/PJ_01_local_maple/step/model.py\", line 49, in forward\n","    return self.model(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 447, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 444, in _conv_forward\n","    self.padding, self.dilation, self.groups)\n","RuntimeError: Given groups=1, weight of size [64, 22, 4, 4], expected input[4, 24, 256, 192] to have 22 channels, but got 24 channels instead\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ic_Vs6tbpSMp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655299488192,"user_tz":-540,"elapsed":8217,"user":{"displayName":"코쿤팬","userId":"14151456840722636307"}},"outputId":"b3b0c0dc-9ad8-4432-e8a3-c122555aad85"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(batch_size=4, checkpoint='checkpoint/tom/tom_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='data', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='tom', radius=5, result_dir='result', shuffle=False, stage='TOM', tensorboard_dir='tensorboard', workers=4)\n","Start to test stage: TOM, named: tom!\n","*** train_dataset is DONE! ***\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","*** train_loader is DONE! ***\n","*** visualization code is DONE! ***\n","*** TOM model is Loaded! ***\n","Dataset size: 00020!\n","Traceback (most recent call last):\n","  File \"step/test.py\", line 172, in <module>\n","    main()\n","  File \"step/test.py\", line 164, in main\n","    test_tom(opt, train_loader, model, board)\n","  File \"step/test.py\", line 99, in test_tom\n","    for step, inputs in enumerate(test_loader.data_loader):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1224, in _next_data\n","    return self._process_data(data)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1250, in _process_data\n","    data.reraise()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 457, in reraise\n","    raise exception\n","RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n","    data = fetcher.fetch(index)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/content/drive/MyDrive/gan/PJ_01_local_maple/step/dataset.py\", line 106, in __getitem__\n","    im_c = im * pcm + (1 - pcm) # [-1,1], fill 1 for other parts\n","RuntimeError: The size of tensor a (192) must match the size of tensor b (3) at non-singleton dimension 2\n","\n"]}],"source":["! python step/test.py --name tom --stage TOM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoint/tom/tom_final.pth"]},{"cell_type":"code","source":[""],"metadata":{"id":"THh6qCIl8Dmk"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"main4colab.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}